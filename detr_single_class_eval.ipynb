{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header_title"
      },
      "source": [
        "# RF-DETR Model Evaluation for Single-Class Vehicle Detection\n",
        "\n",
        "**Research Project**: Comparative Analysis of CNN vs Vision Transformer\n",
        "\n",
        "**Author**: Abdullah Waraich\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "First, let's check GPU availability and install the required libraries for RF-DETR evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu_check"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install -q rfdetr==1.2.1 supervision==0.26.1 scikit-learn seaborn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_section"
      },
      "source": [
        "## 2. Upload Model and Dataset\n",
        "\n",
        "Upload trained RF-DETR model (.pth file) and test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_files"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "print(\" Upload modeel (.pth file) and dataset zip file\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process uploaded files\n",
        "model_path = None\n",
        "dataset_path = None\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.pth'):\n",
        "        model_path = filename\n",
        "        print(f\"âœ… Model found: {filename}\")\n",
        "    elif filename.endswith('.zip'):\n",
        "        # Extract dataset\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('test_dataset')\n",
        "        dataset_path = 'test_dataset'\n",
        "        print(f\"âœ… Dataset extracted to: {dataset_path}\")\n",
        "\n",
        "        # Show dataset structure\n",
        "        print(\"\\nðŸ“ Dataset structure:\")\n",
        "        for root, dirs, files in os.walk(dataset_path):\n",
        "            level = root.replace(dataset_path, '').count(os.sep)\n",
        "            indent = ' ' * 2 * level\n",
        "            print(f\"{indent}{os.path.basename(root)}/\")\n",
        "            subindent = ' ' * 2 * (level + 1)\n",
        "            for file in files[:3]:  # Show first 3 files\n",
        "                print(f\"{subindent}{file}\")\n",
        "            if len(files) > 3:\n",
        "                print(f\"{subindent}... and {len(files)-3} more files\")\n",
        "\n",
        "if not model_path:\n",
        "    print(\"No .pth model file found. Please upload your trained RF-DETR model.\")\n",
        "if not dataset_path:\n",
        "    print(\"No dataset zip file found. Please upload your test dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_section"
      },
      "source": [
        "## 3. Load Model and Dataset\n",
        "\n",
        "Load the RF-DETR model and prepare the test dataset for single-class vehicle detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_model"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from rfdetr import RFDETRMedium\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Load RF-DETR model with trained weights\n",
        "try:\n",
        "    model = RFDETRMedium(pretrain_weights=model_path)\n",
        "    print(\"RF-DETR model loaded successfully!\")\n",
        "\n",
        "    # Optimize for inference\n",
        "    model.optimize_for_inference()\n",
        "    print(\"Model optimized for inference!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    raise\n",
        "\n",
        "# Load test dataset in COCO format\n",
        "print(\"\\n Loading test dataset\")\n",
        "\n",
        "try:\n",
        "    # Look for COCO annotation file\n",
        "    coco_files = []\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.json') and 'annotation' in file.lower():\n",
        "                coco_files.append(os.path.join(root, file))\n",
        "\n",
        "    if not coco_files:\n",
        "        # Look for any JSON file\n",
        "        for root, dirs, files in os.walk(dataset_path):\n",
        "            for file in files:\n",
        "                if file.endswith('.json'):\n",
        "                    coco_files.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"Found annotation files: {coco_files}\")\n",
        "\n",
        "    # Find images directory\n",
        "    images_dir = None\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        if 'images' in os.path.basename(root).lower() or any(f.lower().endswith(('.jpg', '.jpeg', '.png')) for f in files):\n",
        "            images_dir = root\n",
        "            break\n",
        "\n",
        "    if not images_dir:\n",
        "        images_dir = dataset_path  # Fallback to root\n",
        "\n",
        "    print(f\"Images directory: {images_dir}\")\n",
        "\n",
        "    # Load dataset using supervision\n",
        "    test_ds = sv.DetectionDataset.from_coco(\n",
        "        images_directory_path=images_dir,\n",
        "        annotations_path=coco_files[0]\n",
        "    )\n",
        "\n",
        "    print(f\"Dataset loaded successfully!\")\n",
        "    print(f\"Dataset classes: {test_ds.classes}\")\n",
        "    print(f\"Number of test images: {len(test_ds)}\")\n",
        "\n",
        "    # Define single class for evaluation\n",
        "    CLASSES = ['vehicle']  # Single class\n",
        "\n",
        "    print(f\"\\n Model Configuration:\")\n",
        "    print(f\"  Target class: {CLASSES[0]}\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inference_section"
      },
      "source": [
        "## 4. Run Inference with Timing Analysis\n",
        "\n",
        "Run inference on all test images and measure performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_inference"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Running RF-DETR inference on test dataset\")\n",
        "print(f\"Processing {len(test_ds)} total images\")\n",
        "print(f\"Class to be detected: {CLASSES[0]}\")\n",
        "\n",
        "# Storage for results\n",
        "all_predictions = []\n",
        "all_ground_truth = []\n",
        "inference_times = []\n",
        "image_paths = []\n",
        "\n",
        "# Process each image in the dataset\n",
        "for i in tqdm(range(len(test_ds)), desc=\"Running inference\"):\n",
        "    try:\n",
        "        path, image, annotations = test_ds[i]\n",
        "        image_paths.append(path)\n",
        "\n",
        "        # Load image for model\n",
        "        image_pil = Image.open(path)\n",
        "\n",
        "        # Measure inference time\n",
        "        start_time = time.time()\n",
        "        detections = model.predict(image_pil, threshold=0.5)\n",
        "        end_time = time.time()\n",
        "\n",
        "        inference_time = end_time - start_time\n",
        "        inference_times.append(inference_time)\n",
        "\n",
        "        # Store predictions (no class filtering needed for single class)\n",
        "        all_predictions.append(detections)\n",
        "\n",
        "        # Store ground truth annotations\n",
        "        all_ground_truth.append(annotations)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {i}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\nInference complete\")\n",
        "print(f\"Average inference time: {np.mean(inference_times):.4f} seconds\")\n",
        "print(f\"Average FPS: {1/np.mean(inference_times):.2f}\")\n",
        "print(f\"Processed {len(all_predictions)} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "metrics_section"
      },
      "source": [
        "## 5. Calculate Performance Metrics\n",
        "\n",
        "Calculate performance metrics for vehicle detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "calculate_metrics"
      },
      "outputs": [],
      "source": [
        "from supervision.metrics import MeanAveragePrecision\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Calculating Performance Metrics\")\n",
        "\n",
        "\n",
        "# Calculate mAP using supervision\n",
        "map_metric = MeanAveragePrecision()\n",
        "map_result = map_metric.update(all_predictions, all_ground_truth).compute()\n",
        "\n",
        "print(\"MEAN AVERAGE PRECISION (mAP) RESULTS:\")\n",
        "print(f\"mAP@0.5: {map_result.map50:.3f}\")\n",
        "print(f\"mAP@0.5:0.95: {map_result.map50_95:.3f}\")\n",
        "print(f\"mAP@0.75: {map_result.map75:.3f}\")\n",
        "\n",
        "# Calculate precision, recall and F1 Score\n",
        "print(\"\\nPRECISION, RECALL, F1-SCORE ANALYSIS:\")\n",
        "\n",
        "# Create binary classification arrays for vehicle detection\n",
        "all_pred_binary = []\n",
        "all_true_binary = []\n",
        "\n",
        "for pred, gt in zip(all_predictions, all_ground_truth):\n",
        "    # Binary: has vehicle or not\n",
        "    has_prediction = len(pred) > 0\n",
        "    has_ground_truth = len(gt) > 0\n",
        "\n",
        "    all_pred_binary.append(1 if has_prediction else 0)\n",
        "    all_true_binary.append(1 if has_ground_truth else 0)\n",
        "\n",
        "# Calculate binary metrics\n",
        "all_pred_binary = np.array(all_pred_binary)\n",
        "all_true_binary = np.array(all_true_binary)\n",
        "\n",
        "if np.sum(all_true_binary) > 0:  # Only if we have positive samples\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_true_binary, all_pred_binary, average='binary', zero_division=0\n",
        "    )\n",
        "\n",
        "    print(f\"\\n{CLASSES[0].upper()} DETECTION:\")\n",
        "    print(f\"  Precision: {precision:.3f}\")\n",
        "    print(f\"  Recall: {recall:.3f}\")\n",
        "    print(f\"  F1-Score: {f1:.3f}\")\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    total_images = len(all_true_binary)\n",
        "    true_positives = np.sum((all_true_binary == 1) & (all_pred_binary == 1))\n",
        "    false_positives = np.sum((all_true_binary == 0) & (all_pred_binary == 1))\n",
        "    false_negatives = np.sum((all_true_binary == 1) & (all_pred_binary == 0))\n",
        "    true_negatives = np.sum((all_true_binary == 0) & (all_pred_binary == 0))\n",
        "\n",
        "    accuracy = (true_positives + true_negatives) / total_images\n",
        "\n",
        "    print(f\"\\n DETAILED METRICS:\")\n",
        "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
        "    print(f\"  True Positives: {true_positives}\")\n",
        "    print(f\"  False Positives: {false_positives}\")\n",
        "    print(f\"  False Negatives: {false_negatives}\")\n",
        "    print(f\"  True Negatives: {true_negatives}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\n{CLASSES[0].upper()}: No ground truth instances found\")\n",
        "    precision = recall = f1 = accuracy = 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "confusion_section"
      },
      "source": [
        "## 6. Generate Confusion Matrix\n",
        "\n",
        "Create and visualize the confusion matrix for vehicle detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "confusion_matrix"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(\"Generating Confusion Matrix\")\n",
        "\n",
        "# Create confusion matrix for binary classification (vehicle/no vehicle)\n",
        "binary_classes = ['No Vehicle', 'Vehicle']\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(all_true_binary, all_pred_binary, labels=[0, 1])\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=binary_classes,\n",
        "            yticklabels=binary_classes)\n",
        "plt.title('RF-DETR Confusion Matrix\\nSingle-Class Vehicle Detection',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Predicted', fontsize=12)\n",
        "plt.ylabel('True', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\n DETAILED CLASSIFICATION RESULTS:\")\n",
        "print(classification_report(all_true_binary, all_pred_binary,\n",
        "                          target_names=binary_classes,\n",
        "                          zero_division=0))\n",
        "\n",
        "print(f\"\\n Summary Statistics:\")\n",
        "print(f\"  Total images: {len(all_true_binary)}\")\n",
        "print(f\"  Images with vehicles (GT): {np.sum(all_true_binary)}\")\n",
        "print(f\"  Images with vehicles (Pred): {np.sum(all_pred_binary)}\")\n",
        "print(f\"  Detection accuracy: {accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "timing_section"
      },
      "source": [
        "## 7. Inference Time Analysis\n",
        "\n",
        "Analyze the computational efficiency of the RF-DETR model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "timing_analysis"
      },
      "outputs": [],
      "source": [
        "print(\"RF-DETR INFERENCE TIME ANALYSIS\")\n",
        "\n",
        "# Calculate timing statistics\n",
        "avg_time = np.mean(inference_times)\n",
        "std_time = np.std(inference_times)\n",
        "min_time = np.min(inference_times)\n",
        "max_time = np.max(inference_times)\n",
        "fps = 1 / avg_time\n",
        "\n",
        "print(f\"Timing Statistics:\")\n",
        "print(f\"  Average time per image: {avg_time:.4f} seconds\")\n",
        "print(f\"  Standard deviation: {std_time:.4f} seconds\")\n",
        "print(f\"  Minimum time: {min_time:.4f} seconds\")\n",
        "print(f\"  Maximum time: {max_time:.4f} seconds\")\n",
        "print(f\"  Average FPS: {fps:.2f}\")\n",
        "\n",
        "# Plot inference time distribution\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(inference_times, bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
        "plt.axvline(avg_time, color='red', linestyle='--',\n",
        "           label=f'Mean: {avg_time:.4f}s')\n",
        "plt.xlabel('Inference Time (seconds)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('RF-DETR Inference Time Distribution')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(inference_times[:100], marker='o', markersize=2, alpha=0.7, color='orange')\n",
        "plt.axhline(avg_time, color='red', linestyle='--',\n",
        "           label=f'Mean: {avg_time:.4f}s')\n",
        "plt.xlabel('Image Index')\n",
        "plt.ylabel('Inference Time (seconds)')\n",
        "plt.title('Inference Time per Image (First 100)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization_section"
      },
      "source": [
        "## 8. Visual Results Analysis\n",
        "\n",
        "Visualize detection results to assess RF-DETR performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visual_results"
      },
      "outputs": [],
      "source": [
        "print(\"VISUAL RESULTS ANALYSIS\")\n",
        "\n",
        "# Setup visualization components\n",
        "color_palette = sv.ColorPalette.from_hex([\n",
        "    \"#FF6B6B\", \"#4ECDC4\", \"#45B7D1\", \"#96CEB4\", \"#FECA57\", \"#FF9FF3\"\n",
        "])\n",
        "\n",
        "# Select interesting images for visualization\n",
        "num_samples = min(9, len(all_predictions))\n",
        "sample_indices = np.linspace(0, len(all_predictions)-1, num_samples, dtype=int)\n",
        "\n",
        "result_images = []\n",
        "titles = []\n",
        "\n",
        "for idx in sample_indices:\n",
        "    img_path = image_paths[idx]\n",
        "    pred = all_predictions[idx]\n",
        "    gt = all_ground_truth[idx]\n",
        "\n",
        "    # Load image\n",
        "    image = Image.open(img_path)\n",
        "\n",
        "    # Calculate text scale based on image size\n",
        "    text_scale = sv.calculate_optimal_text_scale(resolution_wh=image.size)\n",
        "    thickness = sv.calculate_optimal_line_thickness(resolution_wh=image.size)\n",
        "\n",
        "    # Create prediction labels (simplified for single class)\n",
        "    pred_labels = [\n",
        "        f\"vehicle {confidence:.2f}\"\n",
        "        for confidence in pred.confidence\n",
        "    ] if len(pred) > 0 else []\n",
        "\n",
        "    # Annotate image with predictions\n",
        "    annotated_image = image.copy()\n",
        "\n",
        "    # Draw predictions in color\n",
        "    if len(pred) > 0:\n",
        "        bbox_annotator = sv.BoxAnnotator(color=color_palette, thickness=thickness)\n",
        "        label_annotator = sv.LabelAnnotator(\n",
        "            color=color_palette,\n",
        "            text_color=sv.Color.WHITE,\n",
        "            text_scale=text_scale\n",
        "        )\n",
        "        annotated_image = bbox_annotator.annotate(annotated_image, pred)\n",
        "        annotated_image = label_annotator.annotate(annotated_image, pred, pred_labels)\n",
        "\n",
        "    # Add ground truth boxes in white outline for comparison\n",
        "    if len(gt) > 0:\n",
        "        import cv2\n",
        "        annotated_array = np.array(annotated_image)\n",
        "        for box in gt.xyxy:\n",
        "            x1, y1, x2, y2 = box.astype(int)\n",
        "            cv2.rectangle(annotated_array, (x1, y1), (x2, y2), (255, 255, 255), max(1, thickness//2))\n",
        "        annotated_image = Image.fromarray(annotated_array)\n",
        "\n",
        "    result_images.append(annotated_image)\n",
        "\n",
        "    # Create title with detection count\n",
        "    gt_count = len(gt) if gt is not None else 0\n",
        "    pred_count = len(pred) if pred is not None else 0\n",
        "    titles.append(f\"GT: {gt_count} | Pred: {pred_count}\")\n",
        "\n",
        "# Display results in grid\n",
        "sv.plot_images_grid(\n",
        "    images=result_images,\n",
        "    grid_size=(3, 3),\n",
        "    titles=titles,\n",
        "    size=(15, 15)\n",
        ")\n",
        "\n",
        "print(\"\\n Legend:\")\n",
        "print(\"  â€¢ Colored boxes: RF-DETR predictions with confidence scores\")\n",
        "print(\"  â€¢ White outlines: Ground truth annotations\")\n",
        "print(\"  â€¢ GT: Ground truth count | Pred: Prediction count\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_section"
      },
      "source": [
        "## 9. Results Summary\n",
        "\n",
        "Summary of all metrics for research comparison with YOLOv11."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "results_summary"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# Create comprehensive results dictionary\n",
        "results_dict = {\n",
        "    'model_info': {\n",
        "        'architecture': 'RF-DETR Medium',\n",
        "        'approach': 'Vision Transformer-based',\n",
        "        'classes': CLASSES,\n",
        "        'num_classes': len(CLASSES),\n",
        "        'detection_type': 'single-class'\n",
        "    },\n",
        "    'dataset_info': {\n",
        "        'num_test_images': len(test_ds),\n",
        "        'image_resolution': '640x640',\n",
        "        'processed_successfully': len(all_predictions)\n",
        "    },\n",
        "    'performance_metrics': {\n",
        "        'mAP': {\n",
        "            'mAP50': float(map_result.map50),\n",
        "            'mAP50_95': float(map_result.map50_95),\n",
        "            'mAP75': float(map_result.map75)\n",
        "        },\n",
        "        'binary_classification': {\n",
        "            'precision': float(precision),\n",
        "            'recall': float(recall),\n",
        "            'f1_score': float(f1),\n",
        "            'accuracy': float(accuracy)\n",
        "        },\n",
        "        'detection_counts': {\n",
        "            'true_positives': int(true_positives),\n",
        "            'false_positives': int(false_positives),\n",
        "            'false_negatives': int(false_negatives),\n",
        "            'true_negatives': int(true_negatives)\n",
        "        }\n",
        "    },\n",
        "    'computational_efficiency': {\n",
        "        'avg_inference_time': float(avg_time),\n",
        "        'std_inference_time': float(std_time),\n",
        "        'min_inference_time': float(min_time),\n",
        "        'max_inference_time': float(max_time),\n",
        "        'avg_fps': float(fps)\n",
        "    },\n",
        "    'evaluation_timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "# Display the summary\n",
        "print(\"RF-DETR EVALUATION SUMMARY\")\n",
        "\n",
        "print(f\" Dataset: {len(test_ds)} test images\")\n",
        "print(f\" Target class: {CLASSES[0]}\")\n",
        "print(\"\\n KEY PERFORMANCE METRICS:\")\n",
        "print(f\"  - mAP@0.5: {map_result.map50:.3f}\")\n",
        "print(f\"  - mAP@0.5:0.95: {map_result.map50_95:.3f}\")\n",
        "print(f\"  - Precision: {precision:.3f}\")\n",
        "print(f\"  - Recall: {recall:.3f}\")\n",
        "print(f\"  - F1-Score: {f1:.3f}\")\n",
        "print(f\"  - Accuracy: {accuracy:.3f}\")\n",
        "print(\"\\n COMPUTATIONAL EFFICIENCY:\")\n",
        "print(f\"  - Average inference time: {avg_time:.4f} seconds\")\n",
        "print(f\"  - Average FPS: {fps:.2f}\")\n",
        "print(f\"  - Processing speed: {len(test_ds)/sum(inference_times):.2f} images/second\")\n",
        "\n",
        "print(\"\\n DETECTION PERFORMANCE:\")\n",
        "print(f\"  - True Positives: {true_positives}\")\n",
        "print(f\"  - False Positives: {false_positives}\")\n",
        "print(f\"  - False Negatives: {false_negatives}\")\n",
        "print(f\"  - True Negatives: {true_negatives}\")\n",
        "\n",
        "# Save results to JSON file\n",
        "with open('rfdetr_single_class_results.json', 'w') as f:\n",
        "    json.dump(results_dict, f, indent=2)\n",
        "\n",
        "print(\"\\n Results saved to: rfdetr_single_class_results.json\")\n",
        "\n",
        "# Download results file\n",
        "try:\n",
        "    files.download('rfdetr_single_class_results.json')\n",
        "    print(\"Results file downloaded successfully!\")\n",
        "except:\n",
        "    print(\"Results file saved locally (download from file panel)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison_section"
      },
      "source": [
        "## 10. Prepare Data for Statistical Comparison\n",
        "\n",
        "Generate detection results in format suitable for McNemar's test comparison with YOLOv11."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison_data"
      },
      "outputs": [],
      "source": [
        "print(\"PREPARING DATA FOR STATISTICAL COMPARISON\")\n",
        "\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    #Calculate Intersection over Union of two bounding boxes\n",
        "    x1_min, y1_min, x1_max, y1_max = box1\n",
        "    x2_min, y2_min, x2_max, y2_max = box2\n",
        "\n",
        "    # Calculate intersection\n",
        "    inter_x_min = max(x1_min, x2_min)\n",
        "    inter_y_min = max(y1_min, y2_min)\n",
        "    inter_x_max = min(x1_max, x2_max)\n",
        "    inter_y_max = min(y1_max, y2_max)\n",
        "\n",
        "    if inter_x_max <= inter_x_min or inter_y_max <= inter_y_min:\n",
        "        return 0.0\n",
        "\n",
        "    inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)\n",
        "\n",
        "    # Calculate union\n",
        "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
        "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "\n",
        "    return inter_area / union_area if union_area > 0 else 0.0\n",
        "\n",
        "# Create per-image detection results for McNemar's test\n",
        "detection_results = []\n",
        "\n",
        "for i, (pred, gt, img_path) in enumerate(zip(all_predictions, all_ground_truth, image_paths)):\n",
        "    from pathlib import Path\n",
        "    img_name = Path(img_path).stem\n",
        "\n",
        "    # Calculate if detection was successful (IoU-based)\n",
        "    has_ground_truth = len(gt) > 0\n",
        "    has_prediction = len(pred) > 0\n",
        "\n",
        "    # Check if any prediction matches ground truth (IoU > 0.5)\n",
        "    detection_success = False\n",
        "    if has_ground_truth and has_prediction:\n",
        "        for gt_box in gt.xyxy:\n",
        "            for pred_box, conf in zip(pred.xyxy, pred.confidence):\n",
        "                if conf > 0.5:\n",
        "                    iou = calculate_iou(gt_box, pred_box)\n",
        "                    if iou > 0.5:\n",
        "                        detection_success = True\n",
        "                        break\n",
        "            if detection_success:\n",
        "                break\n",
        "    elif not has_ground_truth and not has_prediction:\n",
        "        detection_success = True  # Correct negative\n",
        "\n",
        "    detection_results.append({\n",
        "        'image_name': img_name,\n",
        "        'has_ground_truth': has_ground_truth,\n",
        "        'has_prediction': has_prediction,\n",
        "        'detection_success': detection_success,\n",
        "        'num_gt_objects': len(gt),\n",
        "        'num_pred_objects': len(pred),\n",
        "        'inference_time': inference_times[i]\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(detection_results)\n",
        "\n",
        "# Calculate success rate\n",
        "success_rate = results_df['detection_success'].mean()\n",
        "print(f\"ðŸŽ¯ Overall Detection Success Rate: {success_rate:.3f}\")\n",
        "\n",
        "# Save detection results for McNemar's test\n",
        "results_df.to_csv('rfdetr_single_class_detection_results.csv', index=False)\n",
        "\n",
        "print(f\"\\n Detection Results Summary:\")\n",
        "print(f\"  - Images with ground truth: {results_df['has_ground_truth'].sum()}\")\n",
        "print(f\"  - Images with predictions: {results_df['has_prediction'].sum()}\")\n",
        "print(f\"  - Successful detections: {results_df['detection_success'].sum()}\")\n",
        "print(f\"  - Success rate: {success_rate:.1%}\")\n",
        "\n",
        "# Generate research comparison summary\n",
        "comparison_summary = f\"\"\"\n",
        "RF-DETR vs YOLOv11 SINGLE-CLASS COMPARISON SUMMARY\n",
        "==================================================\n",
        "\n",
        "Research Project: CNN vs Vision Transformer for Satellite Vehicle Detection\n",
        "Student: Abdullah Waraich (ID: 2401554)\n",
        "Supervisor: Dr. Adrian Clark\n",
        "\n",
        "ARCHITECTURE COMPARISON:\n",
        "â€¢ YOLOv11: CNN-based single-stage detector\n",
        "â€¢ RF-DETR: Vision Transformer-based detector\n",
        "\n",
        "MODEL CONFIGURATION:\n",
        "â€¢ Single class: {CLASSES[0]}\n",
        "â€¢ Simplified evaluation pipeline\n",
        "â€¢ Clean comparison without class imbalance issues\n",
        "\n",
        "KEY FINDINGS:\n",
        "â€¢ RF-DETR mAP@0.5: {map_result.map50:.3f}\n",
        "â€¢ YOLOv11 mAP@0.5: [To be filled from YOLOv11 evaluation]\n",
        "â€¢ RF-DETR inference time: {avg_time:.4f}s\n",
        "â€¢ YOLOv11 inference time: [To be filled from YOLOv11 evaluation]\n",
        "â€¢ RF-DETR accuracy: {accuracy:.3f}\n",
        "â€¢ YOLOv11 accuracy: [To be filled from YOLOv11 evaluation]\n",
        "\n",
        "NEXT STEPS:\n",
        "1. Run McNemar's Test for statistical significance\n",
        "2. Compare computational efficiency\n",
        "3. Analyze failure cases and strengths\n",
        "4. Complete dissertation analysis\n",
        "\n",
        "Files generated:\n",
        "â€¢ rfdetr_single_class_results.json\n",
        "â€¢ rfdetr_single_class_detection_results.csv\n",
        "\"\"\"\n",
        "\n",
        "# Save comparison summary\n",
        "with open('research_comparison_single_class.txt', 'w') as f:\n",
        "    f.write(comparison_summary)\n",
        "\n",
        "print(comparison_summary)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}